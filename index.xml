<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Home on BLAST Working Group</title><link>https://jhublast.github.io/</link><description>Recent content in Home on BLAST Working Group</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 11 Mar 2022 14:19:12 -0500</lastBuildDate><atom:link href="https://jhublast.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Spatial Statistics</title><link>https://jhublast.github.io/research/spatialstatistics/</link><pubDate>Sun, 20 Dec 2020 13:44:30 +1000</pubDate><guid>https://jhublast.github.io/research/spatialstatistics/</guid><description>A central application of spatial statistics is using geographically sparsely sampled data to create spatially continuous maps for policy-making. For example, the figure shows how the PM10 data from a small number of monitoring stations in Europe (left) are used to predict the pollutant&amp;rsquo;s distribution across the region (middle) as well as the probability of it exceeding the regulatory threshold (right). Learn more about spatial statistics here.</description></item><item><title>Abhi Datta</title><link>https://jhublast.github.io/people/abhi-datta/</link><pubDate>Mon, 19 Nov 2018 10:47:58 +1000</pubDate><guid>https://jhublast.github.io/people/abhi-datta/</guid><description>Abhi develops statistical and machine learning methods for large spatial datasets as well as Bayesian models for multi-source epidemiological datasets.</description></item><item><title>Gary Rosner</title><link>https://jhublast.github.io/people/gary-rosner/</link><pubDate>Mon, 19 Nov 2018 10:47:58 +1000</pubDate><guid>https://jhublast.github.io/people/gary-rosner/</guid><description/></item><item><title>Lu Zhang</title><link>https://jhublast.github.io/people/lu-zhang/</link><pubDate>Mon, 19 Nov 2018 10:47:58 +1000</pubDate><guid>https://jhublast.github.io/people/lu-zhang/</guid><description/></item><item><title>Scott Zeger</title><link>https://jhublast.github.io/people/scott-zeger/</link><pubDate>Mon, 19 Nov 2018 10:47:58 +1000</pubDate><guid>https://jhublast.github.io/people/scott-zeger/</guid><description/></item><item><title>Yanxun Xu</title><link>https://jhublast.github.io/people/yanxun-xu/</link><pubDate>Mon, 19 Nov 2018 10:47:58 +1000</pubDate><guid>https://jhublast.github.io/people/yanxun-xu/</guid><description/></item><item><title>Bayesian Computation</title><link>https://jhublast.github.io/research/mcmc/</link><pubDate>Sun, 20 Dec 2020 13:41:30 +1000</pubDate><guid>https://jhublast.github.io/research/mcmc/</guid><description>Markov chain Monte Carlo (MCMC) has been an essential tool for Bayesian statistics, empowering posterior inference for otherwise intractable probabilistic models. While alternatives have emerged, MCMC remains one of the most reliable and broadly applicable approaches to characterize complex posterior distributions common in modern biomedical/public health applications. We push computational limits of Bayesian inference in the era of Big Data through fundamental innovations in MCMC and other computational algorithms.
(Figure: the novel &amp;ldquo;zigzag&amp;rdquo; variant of Hamiltonian Monte Carlo enables statistical phylogenetics software BEAST to infer correlation among relations between gene mutations and biological traits of viruses.</description></item><item><title>Precision Medicine/Health Data Analytics</title><link>https://jhublast.github.io/research/precisionmedicine/</link><pubDate>Sun, 20 Dec 2020 13:41:30 +1000</pubDate><guid>https://jhublast.github.io/research/precisionmedicine/</guid><description>For a specific disease and clinical question of interest, a single data source rarely provide a sufficient number of patients, longitudinal coverage, and breadth of information. Generating actionable clinical insights on how to treat individual patients necessitates integrating patient experiences across multiple data sources. Bayesian inference provides a natural framework to account for the hierarchical structure of such data as well as to incorporate our scientific understanding of the underlying clinical and biological processes.</description></item><item><title>Aki Nishimura</title><link>https://jhublast.github.io/people/aki-nishimura/</link><pubDate>Thu, 20 Dec 2018 13:44:30 +1000</pubDate><guid>https://jhublast.github.io/people/aki-nishimura/</guid><description>Aki uses Bayesian methods and statistical computing to tackle methodological challenges in healthcare analytics and large-scale biomedical applications.</description></item><item><title>Latent Gaussian Model Boosting</title><link>https://jhublast.github.io/events/20211013/</link><pubDate>Fri, 11 Mar 2022 14:19:12 -0500</pubDate><guid>https://jhublast.github.io/events/20211013/</guid><description>Latent Gaussian models and boosting are widely used techniques in statistics and machine learning. Tree-boosting shows excellent predictive accuracy on many data sets, but potential drawbacks are that it assumes conditional independence of samples, produces discontinuous predictions for, e.g., spatial data, and it can have difficulty with high-cardinality categorical variables. Latent Gaussian models, such as Gaussian process and grouped random effects models, are flexible prior models that allow for making probabilistic predictions.</description></item><item><title>Variational Methods for Latent Variable Problems: Part I</title><link>https://jhublast.github.io/events/20211027/</link><pubDate>Fri, 11 Mar 2022 14:18:30 -0500</pubDate><guid>https://jhublast.github.io/events/20211027/</guid><description>Many practical problems in statistical inference involve &amp;ldquo;latent&amp;rdquo; variables, by which I will mean high-dimensional, unobserved nuisance parameters or missing data which must be accounted for when performing inference on some lower-dimensional quantity of primary interest. Common examples include random effects models (the random effects are the latent variables) and mixture models (where the component indicators are the latent variables). I will introduce and discuss variational inference (VI) methods for latent variable problems, drawing connections both with Bayesian approaches (Markov Chain Monte Carlo and the maximum a-posteriori estimator) and frequentist approaches (maximum likelihood estimators and the EM algorithm).</description></item><item><title>Variational Methods for Latent Variable Problems: Part II</title><link>https://jhublast.github.io/events/20211110/</link><pubDate>Fri, 11 Mar 2022 14:17:34 -0500</pubDate><guid>https://jhublast.github.io/events/20211110/</guid><description>Many practical problems in statistical inference involve &amp;ldquo;latent&amp;rdquo; variables, by which I will mean high-dimensional, unobserved nuisance parameters or missing data which must be accounted for when performing inference on some lower-dimensional quantity of primary interest. Common examples include random effects models (the random effects are the latent variables) and mixture models (where the component indicators are the latent variables). I will introduce and discuss variational inference (VI) methods for latent variable problems, drawing connections both with Bayesian approaches (Markov Chain Monte Carlo and the maximum a-posteriori estimator) and frequentist approaches (maximum likelihood estimators and the EM algorithm).</description></item><item><title>Variational Methods for Latent Variable Problems: Part III</title><link>https://jhublast.github.io/events/20211117/</link><pubDate>Tue, 08 Mar 2022 23:52:36 -0500</pubDate><guid>https://jhublast.github.io/events/20211117/</guid><description>Many practical problems in statistical inference involve &amp;ldquo;latent&amp;rdquo; variables, by which I will mean high-dimensional, unobserved nuisance parameters or missing data which must be accounted for when performing inference on some lower-dimensional quantity of primary interest. Common examples include random effects models (the random effects are the latent variables) and mixture models (where the component indicators are the latent variables). I will introduce and discuss variational inference (VI) methods for latent variable problems, drawing connections both with Bayesian approaches (Markov Chain Monte Carlo and the maximum a-posteriori estimator) and frequentist approaches (maximum likelihood estimators and the EM algorithm).</description></item><item><title>Spatial meshing for general Bayesian multivariate models</title><link>https://jhublast.github.io/events/20220309/</link><pubDate>Tue, 08 Mar 2022 14:58:24 -0500</pubDate><guid>https://jhublast.github.io/events/20220309/</guid><description>Quantifying spatial associations in multivariate geolocated data of different types is achievable via random effects in a Bayesian hierarchical model, but severe computational bottlenecks arise when spatial dependence is encoded as a latent Gaussian process (GP) in the increasingly common large scale data settings on which we focus. The scenario worsens in non-Gaussian models because the reduced analytical tractability leads to additional hurdles to computational efficiency. We introduce methodologies for efficiently computing multivariate Bayesian models of spatially referenced non-Gaussian data.</description></item><item><title>Recent Experiences Conducting Trials using Bayesian Response Adaptive Randomization</title><link>https://jhublast.github.io/events/20220223/</link><pubDate>Tue, 08 Mar 2022 14:57:14 -0500</pubDate><guid>https://jhublast.github.io/events/20220223/</guid><description>I will discuss my experiences coordinating two recent clinical trials in out-of-hospital cardiac arrest that used Bayesian response adaptive randomization designs, and present some methodological innovations to improve implementation and understand the potential benefit these designs offer. I will discuss the ACCESS trial (Clinicaltrials.gov ID: NCT03119571), which sought to compare the efficacy of two standards or care: direct admission to the cardiac catheter laboratory versus the ICU; and the ARREST trial (NCT03880565), which sought to evaluate the efficacy of in-transit ECMO-facilitated resuscitation versus standard Advanced Cardiac Life Support (ACLS) resuscitation.</description></item><item><title>A Bayesian predictive platform design for proof of concept and dose finding using early and late endpoints</title><link>https://jhublast.github.io/events/20220209/</link><pubDate>Tue, 08 Mar 2022 14:55:53 -0500</pubDate><guid>https://jhublast.github.io/events/20220209/</guid><description>Evaluating long-term benefits of potential new treatments for chronic diseases can be very time-consuming and costly. We propose a Bayesian predictive platform design that provides a unified framework for evaluating multiple investigational agents in a multistage, randomized controlled trial. The design expedites the drug evaluation process and reduces development costs by including dose finding, futility and superiority monitoring, and enrichment, while avoiding over-allocating patients to a shared placebo or active control arm.</description></item></channel></rss>